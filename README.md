# Projet de Scoring de Cr√©dit avec FastAPI et Streamlit  

## Description des Donn√©es  
Les donn√©es utilis√©es dans ce projet proviennent du dataset **Home Credit Default Risk**, disponible sur [Kaggle](https://www.kaggle.com/c/home-credit-default-risk). Ce dataset contient des informations financi√®res et personnelles sur les clients et permet de pr√©dire la probabilit√© qu‚Äôun client fasse d√©faut sur son cr√©dit.

Le dataset se compose de plusieurs fichiers. Cependant pour ce projet nous avons choisi de travailler uniquement avec les deux fichiers suivants :  
- **application_train.csv** : Donn√©es d‚Äôentra√Ænement avec les informations des clients (√¢ge, revenu, statut familial) et la variable cible **TARGET** (1 = d√©faut, 0 = non d√©faut).  
- **application_test.csv** : Donn√©es utilis√©es pour tester le mod√®le apr√®s l'entra√Ænement sur de nouvelles donn√©es en production.

## Objectifs du Projet  
Ce projet propose une solution compl√®te pour √©valuer le risque de d√©faut de cr√©dit des clients, combinant l‚Äôanalyse de donn√©es, l‚Äôapprentissage automatique, et une interface utilisateur interactive.
- Cr√©er un mod√®le de classification supervis√© pour pr√©dire le risque de d√©faut de paiement des clients.  
- Exposer le mod√®le via une **API FastAPI** afin de pouvoir l'utiliser pour des pr√©dictions en ligne.  
- Cr√©er une interface **Streamlit** interactive pour faciliter l'utilisation du mod√®le.  
- D√©ployer l‚ÄôAPI et l‚Äôapplication Streamlit sur Render pour une utilisation facile et en ligne.

## Fonctionnalit√©s  
Ces fonctionnalit√©s sont accessibles via [l'application d√©ploy√©e sur Render](https://scoring-client-dashboard.onrender.com) :

### API  
L'API permet de :  
- **Retourner la probabilit√©** qu'un client rembourse son cr√©dit.  
- **Afficher l'interpr√©tabilit√©** de la pr√©diction (variables les plus contributives).  

### Dashboard  
Le tableau de bord interactif permet de :  
- **S√©lectionner un client** via une liste d√©roulante.  
- **Visualiser les d√©tails** du client s√©lectionn√© (√¢ge, revenu, statut familial).  
- **Comparer les donn√©es** du client avec celles des autres clients.  
- **Ex√©cuter une pr√©diction** via le bouton "Run Prediction" pour afficher la probabilit√© de remboursement.

## Installation des D√©pendances  
 Liste des d√©pendances n√©cessaires pour ex√©cuter le projet dans le fichier requirements.txt
  

## Structure du Projet

- **app/** : Contient les fichiers li√©s √† l'application et √† l'API.
  - `basic_app.py` : Application principale utilisant FastAPI.
  - `user_interface.py` : Interface utilisateur Streamlit.
  - `utils_ui.py` : Fonctions utilitaires pour l'interface Streamlit.

- **data/** : Donn√©es brutes et pr√©trait√©es.
  - `application_train.csv` : Donn√©es d'entra√Ænement initiales.
  - `application_test.csv` : Donn√©es de test initiales.
  - `final_train.csv` : Donn√©es d'entra√Ænement apr√®s pr√©traitement.
  - `final_test.csv` : Donn√©es de test apr√®s pr√©traitement.

- **notebooks/** : Notebooks Jupyter pour le pr√©traitement et la mod√©lisation.
  - `final_pretraitement.ipynb` : √âtapes de nettoyage et pr√©traitement des donn√©es.
  - `final_modelisation.ipynb` : Construction et √©valuation du mod√®le.

- **models/** : Contient le mod√®le entra√Æn√©.
  - `model_finale.pkl` : Mod√®le final sauvegard√©.

- **reports/** : Rapports g√©n√©r√©s.
  - `data_drift.html` : Rapport d'analyse de d√©rive des donn√©es.


- **clients_api.csv** : Donn√©es des clients utilis√©es pour l'API.
- **client_dashboard.csv** : Donn√©es des clients utilis√©es pour le tableau de bord.




# üìà **√âtapes Cl√©s du Projet**

### **1Ô∏è‚É£ Pr√©traitement des Donn√©es et Contr√¥le du Data Leakage**

Dans cette √©tape, l‚Äôobjectif principal √©tait de pr√©parer les donn√©es et de garantir qu'aucune **fuite de donn√©es** (data leakage) ne se produise. Voici les actions effectu√©es :

#### **Contr√¥le du Data Leakage :**
- **Contamination des ensembles d‚Äôentra√Ænement et de test :**  Le pr√©traitement a √©t√© effectu√© uniquement sur l'ensemble d'entra√Ænement pour √©viter que les donn√©es de test n'influencent le mod√®le. Ensuite, les m√™mes transformations (nettoyage, encodage, √©quilibrage) ont √©t√© appliqu√©es de mani√®re identique sur les donn√©es de test, afin de garantir une √©valuation impartiale du mod√®le.
  
- **Fuite de donn√©es (fuite cible) :**  Pour √©viter ce risque, j‚Äôai v√©rifi√© que les variables explicatives ne contiennent pas d‚Äôinformations qui ne seraient pas disponibles lors de la pr√©diction. Cela inclut l‚Äôanalyse des variables temporelles pour √©viter l'inclusion de donn√©es futures, ainsi qu‚Äôune √©tude approfondie des relations entre les variables explicatives et la cible pour garantir la pertinence des variables s√©lectionn√©es.

#### **Pr√©traitement des Donn√©es :**
R√©sum√© des √©tapes principales :
- **Nettoyage des donn√©es** J'ai √©limin√© les doublons, g√©r√© les valeurs manquantes et les valeurs aberrantes ou atypiques. Puis g√©r√© les modalit√©s et encod√© les variables cat√©gorielles.
 
- **√âquilibrage des classes :**  Pour traiter l'imbalancement des classes, j'ai utilis√© `SMOTE` (Synthetic Minority Over-sampling Technique) pour cr√©er des exemples synth√©tiques de la classe minoritaire, √©quilibrant ainsi la distribution des classes dans les donn√©es.
De plus, pour les mod√®les utilis√©s dans ce projet, j'ai int√©gr√© le `param√®tre class_weight='balanced'`, ce qui permet d'ajuster automatiquement les poids des classes et d'assurer une meilleure prise en compte des classes minoritaires dans l'entra√Ænement du mod√®le.
  

üëâ **[ Voir plus de d√©tails dans le notebook de pr√©traitement](https://github.com/samms307/scoring_client_api/blob/main/Final_pr%C3%A9traitement.ipynb)**



### 2Ô∏è‚É£ **Mod√©lisation**  
Apr√®s avoir pr√©trait√© les donn√©es et √©limin√© tout risque de data leakage, le notebook suivant se concentre sur la construction et l‚Äô√©valuation des mod√®les. Voici les points cl√©s abord√©s dans cette phase :

- **S√©lection du mod√®le :** Nous avons compar√© plusieurs mod√®les, √† commencer par la r√©gression logistique et en incluant des mod√®les plus complexes comme Random Forest et LightGBM, adapt√©s aux donn√©es d√©s√©quilibr√©es. Les performances ont √©t√© √©valu√©es via la m√©trique AUC-ROC, en calculant la moyenne des scores et l'√©cart-type pour mesurer la stabilit√©. Pour assurer une √©valuation robuste, nous avons utilis√© une validation crois√©e stratifi√©e, garantissant que la proportion des classes reste constante dans chaque pli, ce qui √©vite tout biais dans l'entra√Ænement et permet au mod√®le de mieux g√©n√©raliser.

- **Optimisation du seuil de d√©cision :**  L‚Äôajustement du seuil de probabilit√© a √©t√© effectu√© pour optimiser la classification des d√©fauts de paiement, en tenant compte des erreurs de classification (faux n√©gatifs et faux positifs), qui peuvent avoir un impact financier significatif pour l'entreprise.  
  Deux approches ont √©t√© explor√©es :  
  1. **Maximisation de la sensibilit√© et de la sp√©cificit√© :** Trouver un seuil qui √©quilibre les faux positifs et faux n√©gatifs pour am√©liorer la performance globale et minimiser les pertes.  
  2. **Optimisation de la pr√©cision et du rappel :** Prioriser la d√©tection des clients risqu√©s, en particulier pour minimiser les faux n√©gatifs, afin de r√©duire les risques financiers et am√©liorer la gestion du cr√©dit.

  
- **Explicabilit√© du mod√®le :**  Le mod√®le **LightGBM** a √©t√© utilis√© pour les pr√©dictions, et pour en comprendre les d√©cisions, nous avons appliqu√© **LIME** pour expliquer chaque pr√©diction (ex : refus de pr√™t). L'**importance des caract√©ristiques** a permis d'identifier les variables influentes globalement (comme le revenu et l'historique de cr√©dit). Ces m√©thodes assurent que les d√©cisions du mod√®le sont compr√©hensibles et justifiables, r√©pondant ainsi aux exigences r√©glementaires.


- **D√©tection du Data Drift :**
Pour assurer la performance continue du mod√®le en production, nous avons surveill√© l'√©volution des donn√©es avec la `biblioth√®que Evidently`. Evidently permet de d√©tecter le Data Drift en comparant les distributions des donn√©es d'entr√©e en production avec celles des donn√©es d‚Äôentra√Ænement. Cette surveillance du drift des donn√©es aide √† identifier des √©carts significatifs dans les caract√©ristiques des donn√©es, garantissant ainsi que le mod√®le continue √† fournir des pr√©dictions fiables m√™me lorsque les donn√©es changent avec le temps.

[Pour plus de d√©tails sur la d√©tection du data drift, vous pouvez consulter le rapport d'analyse de d√©rive des donn√©es ici](lien_vers_le_rapport)


üëâ **[Voir le notebook de mod√©lisation pour l'interpr√©tation des r√©sultats](https://github.com/samms307/scoring_client_api/blob/main/Final_Mod%C3%A9lisation.ipynb)**






